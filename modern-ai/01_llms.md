# Large Language Models (LLMs)

Large Language Models (LLMs) like GPT-4, Claude, LLaMA, and PaLM have revolutionized natural language understanding and generation. Understanding how LLMs work â€” and how to build, fine-tune, or use them â€” is key to modern AI engineering.

## Learning Objectives

By the end of this module, you should be able to:

- Understand the architecture and training paradigm behind transformer-based LLMs
- Use LLM APIs and open-source models for various tasks (chatbots, summarization, Q&A)
- Evaluate, fine-tune, and deploy LLMs in production settings
- Understand ethical and safety considerations when using LLMs

## Why Itâ€™s Important

LLMs are at the core of modern AI applications. They enable capabilities from code generation to legal research, medical summarization, and AI agents. Engineers with LLM fluency are in high demand across industries.


## Core Topics & Resources

### 1. Foundations of Large Language Models

- [The Illustrated Transformer â€“ Jay Alammar](https://jalammar.github.io/illustrated-transformer/) â€” **Free**
- [Transformers From Scratch â€“ YouTube (Andrej Karpathy)](https://www.youtube.com/watch?v=kCc8FmEb1nY) â€” **Free**
- [Attention Is All You Need (Original Paper)](https://arxiv.org/abs/1706.03762) â€” **Free**

Covers:
- Transformer architecture (self-attention, encoder-decoder)
- Positional encoding, masked attention
- Pre-training and fine-tuning

### 2. Using LLMs via APIs

- [OpenAI GPT API Quickstart](https://platform.openai.com/docs/quickstart) â€” **Free tier available**
- [Anthropic Claude API Guide](https://docs.anthropic.com/) â€” **Free tier available**
- [LangChain for LLM Workflows](https://docs.langchain.com/) â€” **Free**

Covers:
- Prompting techniques (zero-shot, few-shot, chain-of-thought)
- Building chatbots, agents, and tools
- Prompt injection and safety

### 3. Open-Source LLMs

- [Hugging Face Transformers Course](https://huggingface.co/learn/nlp-course/) â€” **Free**
- [Running LLaMA or Mistral on Local Hardware â€“ Guides](https://huggingface.co/blog/llama2) â€” **Free**

Covers:
- Working with models like LLaMA 2, Mistral, Falcon
- Loading models via `transformers` and `transformers.js`
- Tokenizers, inference speed, quantization

### 4. Fine-Tuning & Retrieval-Augmented Generation (RAG)

- [Fine-tuning LLMs with LoRA â€“ Hugging Face](https://huggingface.co/blog/lora) â€” **Free**
- [RAG with Haystack or LangChain â€“ Tutorials](https://www.youtube.com/watch?v=Lk4TzDNsCzU) â€” **Free**
- [Full-Stack LLM Bootcamp â€“ Cohere](https://fullstackdeeplearning.com/llm-bootcamp/) â€” **Free**

Covers:
- Fine-tuning with LoRA/QLoRA
- Embeddings and vector stores (FAISS, ChromaDB)
- Hybrid search and document injection

### 5. Ethics, Safety & Evaluation

- [Responsible AI with LLMs â€“ DeepLearning.AI Short Course](https://www.deeplearning.ai/short-courses/responsible-llms/) â€” **Free**
- [Red Teaming LLMs â€“ Anthropic Blog](https://www.anthropic.com/index/2023/07/red-teaming-ai/) â€” **Free**
- [Prompt Injection Guide â€“ OWASP](https://owasp.org/www-community/attacks/Prompt_Injection) â€” **Free**

Covers:
- Bias, hallucination, toxicity
- Jailbreaks and adversarial prompting
- Model evaluation and safety tools

## Suggested Projects & Practice

- Build a Q&A bot using OpenAI or Claude API
- Fine-tune an open-source LLM on domain-specific data
- Implement RAG over a document set (e.g., company knowledge base)
- Compare models (GPT-4 vs. LLaMA) using the same prompt tasks

## Checkpoint: Before You Move On

You should now be able to:

- Use and prompt LLMs effectively via API or open-source libraries
- Fine-tune and deploy LLMs for custom tasks
- Understand core risks and limitations of LLM-based systems

ðŸ”— Next: [Agentic AI â†’](./02_agentic-ai.md)
